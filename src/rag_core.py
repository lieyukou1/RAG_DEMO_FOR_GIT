"""
    æ ¸å¿ƒRAGé€»è¾‘
"""
import dashscope
import chromadb
from src.embeddings import QwenEmbeddingFunction
from src.config import *


# ==================== æ–‡æ¡£å¤„ç†å‡½æ•° ====================
def load_documents_from_file(file_path=KNOWLEDGE_FILE):
    """ä»æ–‡ä»¶ä¸­è¯»å–æ–‡æ¡£å¹¶æŒ‰æ®µè½åˆ†å‰²"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    # æŒ‰æ®µè½åˆ†å‰²ï¼ˆæ¯ä¸ªæ®µè½æ˜¯ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼‰
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    return paragraphs


# ==================== æ ¸å¿ƒRAGå‡½æ•° ====================
collection = None


def get_collection():
    global collection
    if collection is None:
        print("æ­£åœ¨åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        collection = initialize_vector_database()
    return collection


def retrieve_context(collection, question, top_k=TOP_K_RESULTS):
    """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
    results = collection.query(
        query_texts=[question],
        n_results=top_k
    )

    print(f"\nğŸ” æ£€ç´¢åˆ°çš„æ–‡æ¡£:")
    for i, doc in enumerate(results['documents'][0], 1):
        print(f"  {i}. {doc[:100]}...")  # åªæ‰“å°å‰100å­—ç¬¦
    print()

    context = "\n".join(results['documents'][0])
    return context


def ask_question(question: str, prompt_template=TEACHER_PROMPT_TEMPLATE) -> str:
    """æ ¸å¿ƒé—®ç­”å‡½æ•°"""
    # è·å–collection
    current_collection = get_collection()

    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    context = retrieve_context(current_collection, question)

    # 2. æ„é€ æç¤ºè¯
    prompt = prompt_template.format(context=context, question=question)

    # 3. è°ƒç”¨é€šä¹‰åƒé—®ç”Ÿæˆç­”æ¡ˆ
    response = dashscope.Generation.call(
        model='qwen-plus',
        prompt=prompt,
        result_format='message'
    )

    if response.status_code == 200:
        return response.output.choices[0].message.content
    else:
        return f"è°ƒç”¨å¤±è´¥: {response.message}"


# ==================== åˆå§‹åŒ–å‘é‡æ•°æ®åº“ ====================
def initialize_vector_database():
    global collection


    """åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“å¹¶åŠ è½½æ–‡æ¡£"""
    client = chromadb.Client()
    try:
        collection = client.create_collection(
            name=VECTOR_DB_NAME,
        )
        print(f"âœ… æ‰¾åˆ°ç°æœ‰é›†åˆ: {VECTOR_DB_NAME} (å·²æœ‰ {collection.count()} ä¸ªæ–‡æ¡£)")
    except:
        # é›†åˆä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é›†åˆ
        print(f"ğŸ†• åˆ›å»ºæ–°é›†åˆ: {VECTOR_DB_NAME}")
        collection = client.create_collection(
            name=VECTOR_DB_NAME,
            embedding_function=QwenEmbeddingFunction()
        )

    if collection.count() == 0:
        print("æ­£åœ¨åŠ è½½æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“...")
        documents = load_documents_from_file()
        for i, doc in enumerate(documents):
            collection.add(
                documents=[doc],
                ids=[f"doc_{i}"]
            )

        print(f"âœ… å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")
    else:
        print(f"âœ… é›†åˆå·²æœ‰ {collection.count()} ä¸ªæ–‡æ¡£ï¼Œæ— éœ€é‡å¤æ·»åŠ ")
    return collection


# ==================== å¯¹è¯å†å²ç®¡ç† ====================
conversation_history = []


def ask_question_with_history(question):
    """å¸¦å†å²ä¸Šä¸‹æ–‡çš„é—®ç­”"""
    answer = ask_question(question)

    # ä¿å­˜åˆ°å†å²
    conversation_history.append(f"Q: {question}")
    conversation_history.append(f"A: {answer}")

    # ä¿æŒå†å²çª—å£å¤§å°
    if len(conversation_history) > HISTORY_WINDOW_SIZE * 2:
        conversation_history.pop(0)
        conversation_history.pop(0)

    return answer


def get_recent_history(window_size=HISTORY_WINDOW_SIZE):
    """è·å–æœ€è¿‘çš„å¯¹è¯å†å²"""
    return conversation_history[-(window_size * 2):] if conversation_history else []
