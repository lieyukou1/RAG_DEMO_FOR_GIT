{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "å¥½çš„ï¼è¿™æ˜¯ç¬¬äºŒå¤©çš„å­¦ä¹ ä»»åŠ¡å¤§çº²ï¼ŒåŸºäºä½ çš„æ—¶é—´æƒ…å†µå’Œæ˜¨å¤©å®Œæˆçš„åŸºç¡€ã€‚\n",
    "\n",
    "## ğŸ“… **ç¬¬äºŒå¤©ä»»åŠ¡å¤§çº²**\n",
    "\n",
    "### **æ ¸å¿ƒç›®æ ‡ï¼š**\n",
    "å°†RAG demoå‡çº§ä¸º**å¯å±•ç¤ºã€å¯éƒ¨ç½²**çš„é¡¹ç›®\n",
    "\n",
    "### **æ—¶é—´å®‰æ’å»ºè®®ï¼š**\n",
    "- **æ™šä¸Š22:00-23:30**ï¼šæ ¸å¿ƒåŠŸèƒ½å¼€å‘ï¼ˆ1.5å°æ—¶ï¼‰\n",
    "- **å‘¨æœ«å…¨å¤©**ï¼šç•Œé¢+éƒ¨ç½²ï¼ˆå¦‚æœæ—¶é—´å…è®¸ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **ä»»åŠ¡æ¸…å•**\n",
    "\n",
    "### **ä»»åŠ¡1ï¼šå®Œå–„é¡¹ç›®ç»“æ„ï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šè®©é¡¹ç›®æ›´åƒä¸“ä¸šå·¥ç¨‹\n",
    "\n",
    "```bash\n",
    "ä½ çš„é¡¹ç›®ç»“æ„ï¼š\n",
    "my_rag_demo/\n",
    "â”œâ”€â”€ data/               # æ•°æ®æ–‡ä»¶å¤¹\n",
    "â”‚   â””â”€â”€ knowledge_base.txt\n",
    "â”œâ”€â”€ src/               # æºä»£ç \n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ config.py      # é…ç½®ç®¡ç†\n",
    "â”‚   â”œâ”€â”€ embeddings.py  # Embeddingç±»\n",
    "â”‚   â”œâ”€â”€ rag_core.py    # æ ¸å¿ƒRAGé€»è¾‘\n",
    "â”‚   â””â”€â”€ utils.py       # å·¥å…·å‡½æ•°\n",
    "â”œâ”€â”€ tests/             # æµ‹è¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "â”œâ”€â”€ requirements.txt   # ä¾èµ–åŒ…åˆ—è¡¨\n",
    "â”œâ”€â”€ main.py           # ä¸»å…¥å£æ–‡ä»¶\n",
    "â””â”€â”€ README.md         # é¡¹ç›®æ–‡æ¡£\n",
    "```\n",
    "\n",
    "**å…·ä½“æ“ä½œï¼š**\n",
    "1. åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„\n",
    "2. æ‹†åˆ†ä»£ç åˆ°å¯¹åº”æ–‡ä»¶\n",
    "3. åˆ›å»ºrequirements.txt\n",
    "\n",
    "### **ä»»åŠ¡2ï¼šæ·»åŠ æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ˆ40åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šæ”¯æŒå¤šç§æ ¼å¼ï¼Œä¸ä»…ä»…æ˜¯txt\n",
    "\n",
    "```python\n",
    "# æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š\n",
    "# 1. .txtï¼ˆå·²æ”¯æŒï¼‰\n",
    "# 2. .pdfï¼ˆåŠ åˆ†é¡¹ï¼‰\n",
    "# 3. .mdï¼ˆMarkdownï¼Œç®€å•ï¼‰\n",
    "# 4. ç½‘é¡µURLï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "def load_documents(file_path):\n",
    "    \"\"\"æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½æ–¹å¼\"\"\"\n",
    "    if file_path.endswith('.txt'):\n",
    "        return load_txt(file_path)\n",
    "    elif file_path.endswith('.md'):\n",
    "        return load_markdown(file_path)\n",
    "    # elif file_path.endswith('.pdf'):\n",
    "    #     return load_pdf(file_path)  # éœ€è¦å®‰è£…PyPDF2\n",
    "```\n",
    "\n",
    "### **ä»»åŠ¡3ï¼šåˆ›å»ºç®€å•Webç•Œé¢ï¼ˆ20åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šç”¨Streamlitå¿«é€Ÿæ­å»ºç•Œé¢\n",
    "\n",
    "```python\n",
    "# streamlit_app.pyï¼ˆçº¦20è¡Œä»£ç ï¼‰\n",
    "import streamlit as st\n",
    "from src.rag_core import RAGSystem\n",
    "\n",
    "st.title(\"ğŸ“š æˆ‘çš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹\")\n",
    "question = st.text_input(\"è¯·è¾“å…¥é—®é¢˜ï¼š\")\n",
    "\n",
    "if st.button(\"æé—®\") and question:\n",
    "    with st.spinner(\"æ­£åœ¨æ€è€ƒ...\"):\n",
    "        answer = rag_system.ask(question)\n",
    "        st.success(\"ç­”æ¡ˆï¼š\")\n",
    "        st.write(answer)\n",
    "```\n",
    "\n",
    "### **ä»»åŠ¡4ï¼šé”™è¯¯å¤„ç†å¢å¼ºï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šè®©ç³»ç»Ÿæ›´å¥å£®\n",
    "\n",
    "```python\n",
    "# éœ€è¦å¤„ç†çš„é”™è¯¯ï¼š\n",
    "# 1. APIè°ƒç”¨å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€é¢åº¦ä¸è¶³ï¼‰\n",
    "# 2. æ–‡ä»¶ä¸å­˜åœ¨\n",
    "# 3. ç©ºæŸ¥è¯¢\n",
    "# 4. å‘é‡æ•°æ®åº“è¿æ¥é—®é¢˜\n",
    "\n",
    "def safe_ask_question(question):\n",
    "    \"\"\"å¸¦é”™è¯¯å¤„ç†çš„é—®ç­”\"\"\"\n",
    "    try:\n",
    "        if not question or not question.strip():\n",
    "            return \"é—®é¢˜ä¸èƒ½ä¸ºç©º\"\n",
    "\n",
    "        if len(question) < 2:\n",
    "            return \"é—®é¢˜å¤ªçŸ­ï¼Œè¯·è¯¦ç»†æè¿°\"\n",
    "\n",
    "        return ask_question(question)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}ï¼Œè¯·ç¨åé‡è¯•\"\n",
    "```\n",
    "\n",
    "### **ä»»åŠ¡5ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œ20åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šæå‡å“åº”é€Ÿåº¦\n",
    "\n",
    "```python\n",
    "# ç®€å•ä¼˜åŒ–æªæ–½ï¼š\n",
    "# 1. æ·»åŠ ç¼“å­˜ï¼ˆç›¸åŒé—®é¢˜ç›´æ¥è¿”å›ç­”æ¡ˆï¼‰\n",
    "# 2. é™åˆ¶ç­”æ¡ˆé•¿åº¦\n",
    "# 3. å¼‚æ­¥å¤„ç†ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def ask_with_cache(question):\n",
    "    \"\"\"å¸¦ç¼“å­˜çš„é—®ç­”\"\"\"\n",
    "    if question in cache:\n",
    "        print(\"å‘½ä¸­ç¼“å­˜ï¼\")\n",
    "        return cache[question]\n",
    "\n",
    "    answer = ask_question(question)\n",
    "    cache[question] = answer\n",
    "    return answer\n",
    "```\n",
    "\n",
    "### **ä»»åŠ¡6ï¼šé¡¹ç›®æ–‡æ¡£ï¼ˆ20åˆ†é’Ÿï¼‰**\n",
    "**ç›®æ ‡**ï¼šåˆ›å»ºREADMEï¼Œæ–¹ä¾¿å±•ç¤º\n",
    "\n",
    "```markdown\n",
    "# RAGå­¦ä¹ åŠ©æ‰‹é¡¹ç›®\n",
    "\n",
    "## åŠŸèƒ½ç‰¹æ€§\n",
    "1. ğŸ“– æ”¯æŒä»txtæ–‡ä»¶åŠ è½½çŸ¥è¯†åº“\n",
    "2. ğŸ” åŸºäºé€šä¹‰åƒé—®çš„å‘é‡æ£€ç´¢\n",
    "3. ğŸ’¬ è‡ªç„¶è¯­è¨€é—®ç­”ï¼ˆä¸¤ç§æç¤ºè¯é£æ ¼ï¼‰\n",
    "4. ğŸ—£ï¸ å¯¹è¯å†å²ç®¡ç†\n",
    "5. ğŸŒ ç®€å•çš„Webç•Œé¢\n",
    "\n",
    "## å¿«é€Ÿå¼€å§‹\n",
    "1. å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`\n",
    "2. è®¾ç½®APIå¯†é’¥\n",
    "3. è¿è¡Œï¼š`python main.py`\n",
    "\n",
    "## é¡¹ç›®ç»“æ„\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ **æ ¹æ®æ—¶é—´çµæ´»è°ƒæ•´**\n",
    "\n",
    "### **å¦‚æœä½ ä»Šæ™šåªæœ‰1å°æ—¶ï¼š**\n",
    "**ä¼˜å…ˆçº§æ’åºï¼š**\n",
    "1. âœ… ä»»åŠ¡1ï¼šé¡¹ç›®ç»“æ„ï¼ˆå¿…é¡»ï¼Œ30åˆ†é’Ÿï¼‰\n",
    "2. âœ… ä»»åŠ¡6ï¼šREADMEæ–‡æ¡£ï¼ˆå¿…é¡»ï¼Œ20åˆ†é’Ÿï¼‰\n",
    "3. â³ ä»»åŠ¡3ï¼šç®€å•ç•Œé¢ï¼ˆå¦‚æœè¿˜æœ‰æ—¶é—´ï¼‰\n",
    "\n",
    "### **å¦‚æœä½ æœ‰2å°æ—¶ï¼š**\n",
    "1. âœ… ä»»åŠ¡1ï¼šé¡¹ç›®ç»“æ„\n",
    "2. âœ… ä»»åŠ¡6ï¼šREADMEæ–‡æ¡£\n",
    "3. âœ… ä»»åŠ¡3ï¼šStreamlitç•Œé¢\n",
    "4. âœ… ä»»åŠ¡4ï¼šåŸºç¡€é”™è¯¯å¤„ç†\n",
    "\n",
    "### **å‘¨æœ«å…¨å¤©ï¼ˆæ·±åº¦ä¼˜åŒ–ï¼‰ï¼š**\n",
    "1. éƒ¨ç½²åˆ°Streamlit Cloud\n",
    "2. æ·»åŠ PDFæ”¯æŒ\n",
    "3. å®ç°æ›´å¤æ‚çš„åŠŸèƒ½ï¼ˆå¤šè½®å¯¹è¯ã€ä¸Šä¸‹æ–‡ç®¡ç†ï¼‰\n",
    "4. æ€§èƒ½ä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ **é¢è¯•ä»·å€¼ç‚¹**\n",
    "\n",
    "å®Œæˆç¬¬äºŒå¤©ä»»åŠ¡åï¼Œä½ å¯ä»¥è¯´ï¼š\n",
    "\n",
    "> \"æˆ‘åœ¨ç¬¬ä¸€ç‰ˆçš„åŸºç¡€ä¸Šï¼Œå°†é¡¹ç›®å·¥ç¨‹åŒ–ï¼Œåˆ›å»ºäº†æ¨¡å—åŒ–çš„ä»£ç ç»“æ„ï¼Œæ·»åŠ äº†Webç•Œé¢å’Œé”™è¯¯å¤„ç†ã€‚è¿™ä¸ªé¡¹ç›®ç°åœ¨å¯ä»¥éƒ¨ç½²åˆ°äº‘ç«¯ï¼Œæ”¯æŒæ–‡ä»¶ä¸Šä¼ å’Œè‡ªç„¶å¯¹è¯ã€‚\"\n",
    "\n",
    "## ğŸ“ **ä»Šæ™šå…·ä½“æ­¥éª¤**\n",
    "\n",
    "**å»ºè®®æ‰§è¡Œé¡ºåºï¼š**\n",
    "1. 22:00-22:30ï¼šåˆ›å»ºé¡¹ç›®ç»“æ„ï¼Œæ‹†åˆ†ä»£ç \n",
    "2. 22:30-22:50ï¼šå†™READMEæ–‡æ¡£\n",
    "3. 22:50-23:15ï¼šå°è¯•Streamlitç•Œé¢\n",
    "4. 23:15-23:30ï¼šæµ‹è¯•ã€è®°å½•é—®é¢˜\n",
    "\n",
    "**äº¤ä»˜ç‰©ï¼š**\n",
    "- ä¸€ä¸ªç»“æ„æ¸…æ™°çš„é¡¹ç›®æ–‡ä»¶å¤¹\n",
    "- å¯è¿è¡Œçš„main.py\n",
    "- ç®€å•çš„Webç•Œé¢\n",
    "- é¡¹ç›®æ–‡æ¡£\n",
    "\n",
    "---\n",
    "\n",
    "## â“ **éœ€è¦æˆ‘æä¾›çš„å¸®åŠ©**\n",
    "\n",
    "1. é¡¹ç›®ç»“æ„çš„å…·ä½“ä»£ç æ‹†åˆ†\n",
    "2. Streamlitç•Œé¢çš„å®Œæ•´ç¤ºä¾‹\n",
    "3. é”™è¯¯å¤„ç†çš„æœ€ä½³å®è·µ\n",
    "4. éƒ¨ç½²åˆ°äº‘ç«¯çš„æ­¥éª¤\n",
    "\n",
    "**ä½ æƒ³å…ˆä»å“ªä¸ªä»»åŠ¡å¼€å§‹ï¼Ÿæˆ–è€…éœ€è¦æˆ‘è¯¦ç»†è§£é‡ŠæŸä¸ªä»»åŠ¡çš„å…·ä½“å®ç°ï¼Ÿ**"
   ],
   "id": "1f8260bea371d4a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "å¥½çš„ï¼å¾ˆå®é™…çš„è°ƒæ•´ã€‚**å…ˆæ”¯æŒå¤šä¸ªtxtæ–‡ä»¶**ï¼Œå†è€ƒè™‘å¤šç§æ ¼å¼ï¼Œè¿™æ ·æ›´å¾ªåºæ¸è¿›ã€‚\n",
    "\n",
    "## ğŸ“‹ **æ›´æ–°åçš„ç¬¬äºŒå¤©ä»»åŠ¡æ¸…å•**\n",
    "\n",
    "### **ä»»åŠ¡1ï¼šå®Œå–„é¡¹ç›®ç»“æ„** âœ“\n",
    "### **ä»»åŠ¡1.5ï¼šè¯»å–å¤šä¸ªæ–‡ä»¶** â­æ–°å¢\n",
    "### **ä»»åŠ¡2ï¼šæ·»åŠ æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½**\n",
    "### **ä»»åŠ¡3ï¼šåˆ›å»ºç®€å•Webç•Œé¢**\n",
    "### **ä»»åŠ¡4ï¼šé”™è¯¯å¤„ç†å¢å¼º**\n",
    "### **ä»»åŠ¡5ï¼šé¡¹ç›®æ–‡æ¡£**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **æ–°å¢ä»»åŠ¡1.5ï¼šè¯»å–å¤šä¸ªæ–‡ä»¶ï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "\n",
    "### **ç›®æ ‡ï¼š**\n",
    "- æ”¯æŒä»**æ–‡ä»¶å¤¹**æ‰¹é‡åŠ è½½txtæ–‡ä»¶\n",
    "- ä¿æŒåŸæœ‰çš„å•æ–‡ä»¶åŠ è½½åŠŸèƒ½\n",
    "- è‡ªåŠ¨å¤„ç†æ–‡ä»¶ç¼–ç å’Œæ ¼å¼\n",
    "\n",
    "### **å®ç°æ–¹æ¡ˆï¼š**\n",
    "\n",
    "```python\n",
    "# src/file_loader.py\n",
    "import os\n",
    "\n",
    "def load_single_txt(file_path, encoding='utf-8'):\n",
    "    \"\"\"åŠ è½½å•ä¸ªtxtæ–‡ä»¶\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as f:\n",
    "            content = f.read().strip()\n",
    "        if not content:\n",
    "            print(f\"âš ï¸  æ–‡ä»¶ä¸ºç©º: {file_path}\")\n",
    "            return []\n",
    "        # æŒ‰æ®µè½åˆ†å‰²\n",
    "        paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "        print(f\"âœ…  ä» {os.path.basename(file_path)} åŠ è½½äº† {len(paragraphs)} ä¸ªæ®µè½\")\n",
    "        return paragraphs\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"å°è¯•ç”¨gbkç¼–ç é‡è¯•: {file_path}\")\n",
    "        return load_single_txt(file_path, encoding='gbk')\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ  åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_multiple_txts(folder_path):\n",
    "    \"\"\"åŠ è½½æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰txtæ–‡ä»¶\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"âŒ  æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}\")\n",
    "        return []\n",
    "    \n",
    "    all_paragraphs = []\n",
    "    txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"âš ï¸  æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰txtæ–‡ä»¶: {folder_path}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"ğŸ“  åœ¨ {folder_path} ä¸­æ‰¾åˆ° {len(txt_files)} ä¸ªtxtæ–‡ä»¶\")\n",
    "    \n",
    "    for filename in txt_files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        paragraphs = load_single_txt(file_path)\n",
    "        all_paragraphs.extend(paragraphs)\n",
    "    \n",
    "    print(f\"ğŸ‰  æ€»å…±åŠ è½½äº† {len(all_paragraphs)} ä¸ªçŸ¥è¯†æ®µè½\")\n",
    "    return all_paragraphs\n",
    "\n",
    "def load_documents(source):\n",
    "    \"\"\"é€šç”¨åŠ è½½å‡½æ•°ï¼šæ”¯æŒæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹\"\"\"\n",
    "    if os.path.isfile(source) and source.endswith('.txt'):\n",
    "        return load_single_txt(source)\n",
    "    elif os.path.isdir(source):\n",
    "        return load_multiple_txts(source)\n",
    "    else:\n",
    "        print(f\"âŒ  ä¸æ”¯æŒçš„æ•°æ®æº: {source}\")\n",
    "        return []\n",
    "```\n",
    "\n",
    "### **ä½¿ç”¨ç¤ºä¾‹ï¼š**\n",
    "\n",
    "```python\n",
    "# æ–¹å¼1ï¼šåŠ è½½å•ä¸ªæ–‡ä»¶ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰\n",
    "documents = load_documents(\"data/single_note.txt\")\n",
    "\n",
    "# æ–¹å¼2ï¼šåŠ è½½æ•´ä¸ªæ–‡ä»¶å¤¹\n",
    "documents = load_documents(\"data/knowledge_base/\")\n",
    "\n",
    "# æ–¹å¼3ï¼šæ˜ç¡®æŒ‡å®šå‡½æ•°\n",
    "from src.file_loader import load_multiple_txts\n",
    "documents = load_multiple_txts(\"data/notes/\")\n",
    "```\n",
    "\n",
    "### **æ–‡ä»¶å¤¹ç»“æ„ç¤ºä¾‹ï¼š**\n",
    "\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ knowledge_base/     # çŸ¥è¯†åº“æ–‡ä»¶å¤¹\n",
    "â”‚   â”œâ”€â”€ ml_basics.txt   # æœºå™¨å­¦ä¹ åŸºç¡€\n",
    "â”‚   â”œâ”€â”€ deep_learning.txt  # æ·±åº¦å­¦ä¹ \n",
    "â”‚   â”œâ”€â”€ nlp_notes.txt   # NLPç¬”è®°\n",
    "â”‚   â””â”€â”€ interview_qa.txt # é¢è¯•é¢˜\n",
    "â”œâ”€â”€ single_note.txt    # å•ä¸ªæ–‡ä»¶ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰\n",
    "â””â”€â”€ test_questions.txt # æµ‹è¯•é—®é¢˜é›†\n",
    "```\n",
    "\n",
    "### **å®é™…åº”ç”¨åœºæ™¯ï¼š**\n",
    "\n",
    "```python\n",
    "# åœ¨åˆå§‹åŒ–å‘é‡æ•°æ®åº“æ—¶ä½¿ç”¨\n",
    "def initialize_knowledge_base(knowledge_source=\"data/knowledge_base/\"):\n",
    "    \"\"\"åˆå§‹åŒ–çŸ¥è¯†åº“ï¼Œæ”¯æŒæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹\"\"\"\n",
    "    print(\"æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...\")\n",
    "    \n",
    "    if knowledge_source.endswith('/') and os.path.isdir(knowledge_source):\n",
    "        documents = load_multiple_txts(knowledge_source)\n",
    "    else:\n",
    "        documents = load_single_txt(knowledge_source)\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æº\")\n",
    "        return None\n",
    "    \n",
    "    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆåŸæœ‰é€»è¾‘ï¼‰\n",
    "    collection = create_vector_collection(documents)\n",
    "    return collection\n",
    "```\n",
    "\n",
    "### **é”™è¯¯å¤„ç†å¢å¼ºï¼š**\n",
    "\n",
    "```python\n",
    "def safe_load_documents(source):\n",
    "    \"\"\"å®‰å…¨çš„æ–‡æ¡£åŠ è½½ï¼Œå¸¦è¯¦ç»†æ—¥å¿—\"\"\"\n",
    "    if not os.path.exists(source):\n",
    "        print(f\"âŒ è·¯å¾„ä¸å­˜åœ¨: {source}\")\n",
    "        print(\"æç¤ºï¼š\")\n",
    "        print(\"1. å•ä¸ªæ–‡ä»¶: data/my_notes.txt\")\n",
    "        print(\"2. æ–‡ä»¶å¤¹: data/knowledge_base/\")\n",
    "        return []\n",
    "    \n",
    "    documents = load_documents(source)\n",
    "    \n",
    "    if documents:\n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        total_chars = sum(len(doc) for doc in documents)\n",
    "        avg_length = total_chars / len(documents) if documents else 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š åŠ è½½ç»Ÿè®¡:\")\n",
    "        print(f\"  æ–‡æ¡£æ®µè½æ•°: {len(documents)}\")\n",
    "        print(f\"  æ€»å­—ç¬¦æ•°: {total_chars}\")\n",
    "        print(f\"  å¹³å‡æ®µè½é•¿åº¦: {avg_length:.0f} å­—ç¬¦\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæ ·ä¾‹\n",
    "        print(f\"\\nğŸ“„ æ ·ä¾‹æ®µè½:\")\n",
    "        for i, doc in enumerate(documents[:2], 1):\n",
    "            preview = doc[:100] + \"...\" if len(doc) > 100 else doc\n",
    "            print(f\"  {i}. {preview}\")\n",
    "    \n",
    "    return documents\n",
    "```\n",
    "\n",
    "### **æµ‹è¯•è„šæœ¬ï¼š**\n",
    "\n",
    "```python\n",
    "# test_file_loader.py\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"æµ‹è¯•æ–‡ä»¶åŠ è½½åŠŸèƒ½...\")\n",
    "    \n",
    "    # æµ‹è¯•1ï¼šå•ä¸ªæ–‡ä»¶\n",
    "    print(\"\\n1. æµ‹è¯•å•ä¸ªæ–‡ä»¶:\")\n",
    "    docs1 = load_single_txt(\"data/single_note.txt\")\n",
    "    print(f\"   åŠ è½½æ®µè½: {len(docs1)}\")\n",
    "    \n",
    "    # æµ‹è¯•2ï¼šæ–‡ä»¶å¤¹\n",
    "    print(\"\\n2. æµ‹è¯•æ–‡ä»¶å¤¹:\")\n",
    "    docs2 = load_multiple_txts(\"data/knowledge_base/\")\n",
    "    print(f\"   æ€»æ®µè½æ•°: {len(docs2)}\")\n",
    "    \n",
    "    # æµ‹è¯•3ï¼šé€šç”¨åŠ è½½å™¨\n",
    "    print(\"\\n3. æµ‹è¯•é€šç”¨åŠ è½½å™¨:\")\n",
    "    docs3 = load_documents(\"data/knowledge_base/\")  # æ–‡ä»¶å¤¹\n",
    "    docs4 = load_documents(\"data/single_note.txt\")   # æ–‡ä»¶\n",
    "    \n",
    "    print(\"âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼\")\n",
    "```\n",
    "\n",
    "## ğŸ¯ **ä»Šæ™šä»»åŠ¡å®‰æ’å»ºè®®**\n",
    "\n",
    "### **æ—¶é—´åˆ†é…ï¼ˆæ€»å…±1.5-2å°æ—¶ï¼‰ï¼š**\n",
    "\n",
    "**ç¬¬ä¸€é˜¶æ®µï¼šé¡¹ç›®ç»“æ„ï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "1. åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„\n",
    "2. æ‹†åˆ†ç°æœ‰ä»£ç åˆ°å¯¹åº”æ¨¡å—\n",
    "\n",
    "**ç¬¬äºŒé˜¶æ®µï¼šå¤šæ–‡ä»¶åŠ è½½ï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "1. åˆ›å»º`file_loader.py`\n",
    "2. å®ç°ä¸Šè¿°å‡½æ•°\n",
    "3. æµ‹è¯•åŠ è½½åŠŸèƒ½\n",
    "\n",
    "**ç¬¬ä¸‰é˜¶æ®µï¼šé›†æˆåˆ°ä¸»ç³»ç»Ÿï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "1. ä¿®æ”¹åˆå§‹åŒ–ä»£ç ï¼Œæ”¯æŒæ–‡ä»¶å¤¹\n",
    "2. æ›´æ–°`main.py`\n",
    "3. æµ‹è¯•å®Œæ•´æµç¨‹\n",
    "\n",
    "**ç¬¬å››é˜¶æ®µï¼šåŸºç¡€æ–‡æ¡£ï¼ˆ30åˆ†é’Ÿï¼‰**\n",
    "1. åˆ›å»º`README.md`\n",
    "2. å†™`requirements.txt`\n",
    "3. ç®€å•æµ‹è¯•\n",
    "\n",
    "### **å¦‚æœæ—¶é—´ä¸å¤Ÿçš„ç®€åŒ–ç‰ˆï¼š**\n",
    "\n",
    "```python\n",
    "# æœ€ç®€åŒ–çš„å¤šæ–‡ä»¶æ”¯æŒï¼ˆ15åˆ†é’Ÿï¼‰\n",
    "import glob\n",
    "\n",
    "def load_all_txts(folder_path):\n",
    "    \"\"\"æœ€ç®€å•çš„å¤šæ–‡ä»¶åŠ è½½\"\"\"\n",
    "    all_texts = []\n",
    "    for file_path in glob.glob(f\"{folder_path}/*.txt\"):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "            all_texts.extend(paragraphs)\n",
    "    return all_texts\n",
    "```\n",
    "\n",
    "## ğŸ’¡ **ä¸ºä»€ä¹ˆå…ˆåšå¤šæ–‡ä»¶è€Œä¸æ˜¯å¤šæ ¼å¼ï¼Ÿ**\n",
    "\n",
    "1. **æ›´å®ç”¨**ï¼šçŸ¥è¯†åº“é€šå¸¸ç”±å¤šä¸ªæ–‡ä»¶ç»„æˆ\n",
    "2. **æ›´ç®€å•**ï¼šä¿æŒç»Ÿä¸€æ ¼å¼ï¼ˆtxtï¼‰ï¼Œé¿å…å¤æ‚çš„æ ¼å¼è§£æ\n",
    "3. **æ›´ç¨³å¥**ï¼šå‡å°‘å¤–éƒ¨ä¾èµ–ï¼ˆä¸éœ€è¦PyPDF2ç­‰åº“ï¼‰\n",
    "4. **æ›´å¥½æµ‹è¯•**ï¼šå®¹æ˜“åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "\n",
    "## ğŸš€ **å®Œæˆåçš„æ•ˆæœ**\n",
    "\n",
    "ä½ å¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š\n",
    "```bash\n",
    "# ä½¿ç”¨æ–‡ä»¶å¤¹ä½œä¸ºçŸ¥è¯†åº“\n",
    "python main.py --knowledge_base \"data/my_notes/\"\n",
    "\n",
    "# æˆ–è€…å•ä¸ªæ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰\n",
    "python main.py --knowledge_base \"data/notes.txt\"\n",
    "```\n",
    "\n",
    "**ä»Šæ™šå…ˆä»ä»»åŠ¡1å¼€å§‹ï¼Œé‡åˆ°å…·ä½“é—®é¢˜éšæ—¶é—®æˆ‘ï¼**"
   ],
   "id": "83f54fc7da4bfb28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
